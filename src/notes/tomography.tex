\section{Tomography}

Notes taken from \cite{nielsen_quantum_2011}, only reworded and trimmed down for my benefit.
\todoin{Clean up these notes and put into a Technical Background chapter.}

\subsection{Operator-Sum Representation} % Chapter 8.2.3

Quantum operations can be represented in the \textit{operator-sum representation}. Consider a state
$\rho$ coupled with the environment $\rho_{\text{env}}$ which is transformed by $U$. The final state
$\mathcal{E}(\rho)$ of the system is then
\begin{equation}
    \mathcal{E}(\rho) = \tr[\text{env}]{U (\rho \otimes \rho_{\text{env}}) U^{\dagger}}
\end{equation}
where we trace out the environment to obtain the state of the system alone. To rewrite this in
operator form, we let $\rho_\text{env}$ be a pure state $\ketbra{e_0}{e_0}$ with orthonormal basis
$\ket{e_k}$. Then, we have
\begin{align}
    \mathcal{E}(\rho) &= \sum_k \bra{e_k} U \Big[\rho \otimes \ketbra{e_0}{e_0}\Big] U^{\dagger} \ket{e_k} \\
                      &= \sum_k E_k \rho E_k^{\dagger}
\end{align}

Where $E_k = \braket{e_k | U | e_0}$, and we omit the identities in $I \otimes \ket{e_k}$. See
\href{https://physics.stackexchange.com/questions/276053/trouble-with-operator-sum-representation-of-a-quantum-operation}{this
answer for why}. The operators $E_k$ are known as \textit{operation elements}. This form is
incredibly useful for tomography, which is covered in the following sections. \todoin{Expand this
more}

\subsection{State Tomography}

In the classical world, characterising the dynamics of a system is trivial and known as
\textit{system identification}. The general idea is that we wish to know how the system behaves with
respect to any input, thus uniquely identifying it. In the quantum world, the analogue of this is
called \textit{quantum process tomography}. To understand process tomography, we must first
understand \textit{quantum state tomography}.

State tomography is the procedure of determining an unknown quantum state. This is harder than it
sounds: if we're given an unknown state $\rho$, we can't just measure the state and recover it
immediately way since measurement will \textit{disturb} the original state. In fact, \textit{there
is no quantum measurement which can distinguish non-orthogonal states with certainty}. However, if
we have an \textit{ensemble} of the same quantum state $\rho$, then it's possible to estimate
$\rho$.

If we represent the state of the system using its density matrix $\rho$, we may expand $\rho$ as
\begin{equation}
    \rho = \frac{\tr{\rho}I + \tr{X\rho}X + \tr{Y\rho}Y + \tr{Z\rho}Z}
                {2}
\end{equation}
Note that $\tr{Z\rho}$ can be interpreted as the \textit{expectation} of the observable $Z$.
Therefore, to estimate $\tr{Z\rho}$, we measure the observable $Z$ $m$-times to obtain outcomes
$z_1, \dots, z_m$ and calculate
\begin{equation}
    \tr{Z\rho} \approx \frac{1}{m} \sum_i^m z_i
\end{equation}
In general, this estimate is approximately a Gaussian with mean $\tr{Z\rho}$ and standard deviation
$\Delta(Z) / \sqrt{m}$, where $\Delta(Z)$ is the standard deviation of a single measurement. We can
apply this same method to estimate $\tr{X\rho}X$ and $\tr{Y\rho}Y$; with a large enough sample size
we obtain a good estimate for $\rho$. Additionally, since density matrices have unit trace, we know
that
\begin{equation}
    \tr{\rho} I = I
\end{equation}
This process can be generalised to a density matrix on $n$ qubits as
\begin{equation}
    \rho = \sum_{\vec{v}} \frac{\tr{\sigma_{v_1} \otimes \sigma_{v_2} \otimes \dots \otimes \sigma_{v_n}} \sigma_{v_1} \otimes \sigma_{v_2} \otimes \dots \otimes \sigma_{v_n}}{2^n}
\end{equation}
where $\vec{v} = \left(v_1, \dots, v_n\right)$ with entries $v_i$ chosen from the set $0, 1, 2, 3$,
i.e. each $\sigma_{v_i}$ is a particular Pauli matrix.

% TODO: look over this and possibly get an example? I get kind of what its doing but a concrete
% example would help

\subsection{Process Tomography}

To extend this notion to quantum process tomography is actually quite easy from a theoretical point
of view. If the state space of the system has $d$ dimensions ($d = 2$ for a single qubit), then we
choose $d^2$ pure quantum states $\ket{\psi_d}, \dots, \ket{\psi_{d^2}}$. The corresponding density
matrices $\ketbra{\psi_1}{\psi_1}, \dots, \ketbra{\psi_{d^2}}{\psi_{d^2}}$ for these states should
form a \textit{basis set} for the space of possible density matrices. 

Now, for each state $\ket{\psi_j}$, we prepare the system in that state and then subject it to the
process $\mathcal{E}$. Afterwards, we use state tomography to determine the output state
$\mathcal{E}(\ketbra{\psi_j}{\psi_j})$. Theoretically, this is all that we need to do, since the
matrices $\ketbra{\psi_j}{\psi_j}$ form a basis set, so any other possible density matrices can be
represented as a linear combination of the basis set. e.g.,
\begin{equation}
    \mathcal{E}(\ketbra{\Phi}{\Phi} + \ketbra{\Psi}{\Psi}) = 
    \mathcal{E}(\ketbra{\Phi}{\Phi}) + \mathcal{E}(\ketbra{\Psi}{\Psi})
\end{equation}
However, in practice, it's not that simple since operators are just a `theoretical tool'. We only
have access to measureable quantities. We can instead describe $\mathcal{E}$ using
\textit{operator-sum representation}, where our goal is to determine a set of operation elements
$\{E_i\}$ for $\mathcal{E}$,
\begin{equation} \label{eq:operation_elements}
    \mathcal{E}(\rho) = \sum_i E_i \rho E_i^{\dagger} 
\end{equation}
To obtain these operators from measurements, it is convenient to use a different formulation of
$\mathcal{E}$ from a \textit{fixed} set of operators $\tilde{E}_i$. These fixed operators will form
a basis set for the operators of that state space, so that
\begin{equation}
    E_i = \sum_m e_{im} \tilde{E}_m
\end{equation}
for some set of complex numbers $e_{im}$. We can rewrite Equation \ref{eq:operation_elements} as
\begin{equation} \label{eq:chi_matrix_representation}
    \mathcal{E}(\rho) = \sum_{mn} \tilde{E}_m \rho \tilde{E}_n^{\dagger} \chi_{mn}
\end{equation}
where each $\tilde{E}_i$ is a fixed operator, and $\chi$ is a complex matrix known as the
\textit{chi matrix representation}. $\chi$ is defined as
\begin{equation}
    \chi_{mn} = \sum_i e_{im} e_{in}^*
\end{equation}
Here, we have simply combined the complex numbers $e_{im}$ into a single matrix. By definition, this
is a positive Hermitian matrix. This shows that we can determine $\mathcal{E}$ entirely from $\chi$,
once the set of operators has been fixed. 

Now, let $p_j, 1 \le j \le d^2$ be a set of matrices which form an independent basis for the the
space of $d \times d$ matrices. We can determine each $\mathcal{E}(\rho_j)$ by state tomography, and
then express this as a linear combination of the basis states,
\begin{equation}
    \mathcal{E}(\rho_j) = \sum_k \lambda_{jk} \rho_k
\end{equation}
Since we know $\mathcal{E}(\rho_j)$ via state tomography, we can determine $\lambda_{jk}$ by linear
algebra. i.e. $\mathcal{E}(\rho_j)$ is a known matrix and each $\rho_k$ is known, so we simply need
to solve standard linear equations for each $\lambda_{jk}$. Furthermore, we can write this as
\begin{equation}
    \tilde{E}_m \rho_j \tilde{E}_n^{\dagger} = \sum_k \beta_{jk}^{mn} \rho_k
\end{equation}
where $\beta_{jk}^{mn}$ are complex numbers determined by standard linear algebra algorithms given
the operators $\tilde{E}_m$, $\tilde{E}_n$, and $\rho_j$. Note that the $m$ and $n$ come from the
fixed operators in Equation \ref{eq:chi_matrix_representation}. If we combine the previous two
equations with Equation \ref{eq:chi_matrix_representation}, we get
\begin{equation}
    \sum_k \sum_{mn} \chi_{mn} \beta_{jk}^{mn} \rho_k = \sum_k \lambda_{jk} \rho_k
\end{equation}
From the linear independence of $\rho_k$, it follows that
\begin{equation} \label{eq:chi_relation}
    \sum_{mn} \beta_{jk}^{mn} \chi_{mn} = \lambda_{jk}
\end{equation}
Equation \ref{eq:chi_relation} is a necessary condition for $\chi$ to give the correct quantum
operation $\mathcal{E}$.

We can think of $\chi$ and $\lambda$ as vectors, and $\beta$ as a $d^4 \times d^4$ matrix. Here,
$\beta$ has columns indexed by $mn$ and rows indexed by $jk$. Now, suppose that $\beta$ has an
inverse $\kappa$. $\chi$ is then completely defined by
\begin{equation}
    \chi_{mn} = \sum_{jk} \kappa_{jk}^{mn} \lambda_{jk}
\end{equation}
Which we can write more clearly in matrix form as
\begin{equation}
    \vec{\chi} = \kappa \vec{\lambda}
\end{equation}
Fortunately, once we know $\chi$, we immediately know the operator-sum representation of
$\mathcal{E}$. Suppose that some unitary matrix $U^{\dagger}$ diagonalises $\chi$. Then, we can
construct $E_i$ using
\begin{align}
    \chi_{mn} &= \sum_{xy} U_{mx} d_x \delta_{xy} U^*_{ny} \\
    E_i &= \sqrt{d_i} \sum_j U_{ji} \tilde{E}_j
\end{align}
In summary: $\lambda$ is determined using state tomography, which then determines $\chi$ via
$\vec{\chi} = \kappa \vec{\lambda}$. We can then use $\chi$ to completely determine each $E_i$.

In general $\chi$ will contain $d^4 - d^2$ independent parameters. A linear map from $d \times d$
complex matrices to $d \times d$ matrices is described by $d^4$ independent parameters. $d^2$ comes
from the constraint that $\rho$ must remain Hermitian with unit trace. For a single qubit, we'll
have $2^4 - 2^2 = 12$ parameters, whilst two qubits will have $4^4 - 4^2 = 240$ parameters!  

The above process looks pretty complex. Fortunately, in the case of a single qubit, we can pick
specific fixed operators $\tilde{E}_i$ to simplify the process massively. We select
\begin{align}
    \tilde{E}_0 &= I \\
    \tilde{E}_1 &= X \\
    \tilde{E}_2 &= -iY \\
    \tilde{E}_3 &= Z
\end{align}
For our basis set $\rho_j$, we can prepare the input states $\ket{0}, \ket{1}, \ket{+} = (\ket{0} +
\ket{1}) / \sqrt{2}, \ket{-}= (\ket{0} + i\ket{1}) / \sqrt{2}$. We determine
\begin{align}
    \rho_1' &= \mathcal{E}(\ketbra{0}{0}) \\
    \rho_4' &= \mathcal{E}(\ketbra{1}{1}) \\
    \rho_2' &= \mathcal{E}(\ketbra{1}{0}) = \mathcal{E}(\ketbra{+}{+}) - i\mathcal{E}(\ketbra{-}{-}) - (1 - i)(\rho_1' + \rho_4') / 2 \\
    \rho_3' &= \mathcal{E}(\ketbra{0}{1}) = \mathcal{E}(\ketbra{+}{+}) + i\mathcal{E}(\ketbra{-}{-}) - (1 + i)(\rho_1' + \rho_4') / 2
\end{align}
because $\ketbra{0}{0}, \ketbra{1}{1}, \ketbra{1}{0}, \ketbra{0}{1}$ form a basis for the set of $d
\times d$ matrices.